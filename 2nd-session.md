# 2주차. 1장. 나의 첫 머신러닝(p.25-p.64), 2장. 데이터 다루기(p.65-p.112)

## 1-1. 인공지능과 머신러닝, 딥러닝
- 인공지능이란
    - 사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술.
    - 강인공지능Strong AI or 인공일반지능Artificial General Intelligence: 영화 속 인공지능. 사람과 구분하기 어려운 지능.
    - 약인공지능Week AI: 특정 분야에서 사람의 일을 도와주는 보조 역할.
- 머신러닝이란
    - 규칙을 일일이 프로그래밍하지 않아도 자동으로 데이터에서 규칙을 학습하는 알고리즘을 연구하는 분야. 인공지능의 지능을 구현하기 위한 SW를 담당하는 핵심 분야.
    - 통계학과 깊은 관련.
    - 최근에는 통계나 수학보다는 경험을 바탕으로 발전하는 경우도 많음. ex) 사이킷런scikit-learn 라이브러리.
    - 사이킷런에 포함된 알고리즘들을 사용하면 된다.
- 딥러닝이란
    - 머신러닝 알고리즘 중에 인공신경망을 기반으로 한 방법들을 통칭한 것.
    - 1\) 풍부한 데이터와 2\) 컴퓨터 성능 향상, 그리고 3\) 혁신적인 알고리즘 개발로 가능하게 되었다.
    - 딥러닝 라이브러리는 텐서플로TensorFlow(구글), 파이토치PyTorch(페이스북)이 있다.

## 1-2. 코랩과 주피터 노트북
- 구글 코랩Colab
      - 웹 브라우저에서 무료로 파이썬 프로그램을 테스트하고 저장할 수 있는 서비스. 클라우드 기반 주피터 노트북 개발 환경.
      - 셀cell은 코드 또는 텍스트 덩어리. 코랩에서 실행할 수 있는 최소 단위.
- 텍스트 셀
    - 코랩 노트북의 장점은  코드 설명 문서를 따로 만들지 않아도 코드와 텍스트, 실행 결과까지 담아서 공유할 수 있다.
    - HTML과 마크다운을 혼용해서 사용할 수 있다.
    - 주요 기능 T 제목으로 만들기, B 볼드체, I 이탤릭체, <> 코드 형식으로 바꿔줌, 링크 표시, 이미지 추가, 들여쓰기, 번호 매기기, 글머리 기호, 가로줄 추가, 미리보기 창 위치 변경.
- 코드 셀
    - 코드와 결과가 함께 선택됨.
- 노트북
    - 코랩은 대화식 프로그래밍 환경인 주피터Jupyter를 커스터마이징 한 것.
    - 주피터 프로젝트의 대표 제품이 주피터 노트북.
    - 코랩 노트북은 구글 클라우드의 가상 서버Virtual Machine를 사용.
    - 이 서버의 메모리는 약 12gb, 디스크 공간 100gb. 최대 5개의 가상 서버까지 무료로 열 수 있고, 최대 12시간까지만 실행 가능.
## 1-3. 마켓과 머신러닝
- 생선 분류 문제
    - 생선 데이터 셋의 출처는 캐글. 세계에서 가장 큰 머신러닝 경영 대회 사이트. 많은 데이터와 참고자료도 제공함.
    - 보통의 프로그램은 '누군가 정해준 대로' 30cm 이상이면 도미라고 판단하지만, 머신러닝은 스스로 기준을 찾아서 일을 한다.
    - 여러 개의 도미 데이터를 제공해서 스스로 찾는 것.
    - 여러 개 종류(또는 클래스) 중에서 하나를 구별하는 문제를 분류classification이라고 한다. 이 경우 2개 중 하나 찾는 것은 이진 분류라고 한다.
    - 도미의 길이와 무게로 리스트를 만든다. 각 도미의 특징을 나타낸 것이 "특성 feature"이라고 한다.
    - 각 특성을 점으로 표현하는 것을 산점도라고 하는데 파이썬에서는 맷플롯립matplotlib이라는 패키지로 과학계산용 그래프를 그린다.
    - import란 따로 만들어진 패키지를 사용하기 위해 불러오는 명령이다.
    - 코랩에는 이미 널리 쓰이는 패키지들이 설치되어 있다.
    - 임포트할 때 as 키워드로 이름을 줄여서 쓴다. 줄임말은 미리 알아두는 것이 좋음.
```python
plt.scatter(bream_length, bream_weight)
plt.scatter(smelt_length, smelt_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```
- 첫 번째 머신러닝 프로그램
    - K-최근접 이웃(K-Nearest Neighbors) 알고리즘 사용.
    - 두 리스트를 하나로 합친다.
    - 사이킷런 패키지 사용할 것. 세로 방향의 2차원 리스트를 만들어야 한다.
    - zip( ) 함수로 나열된 리스트에서 각각 원소를 하나씩 꺼내서 반환한다.
    - 이 2차원 리스트에 정답 데이터를 추가해줘야 한다. 문자를 직접 이해 못하니 도미는 1, 빙어는 0으로.
    - 머신러닝에서 2개 구분하는 경우, 찾으려는 대상을 1로 놓고 그 외는 0으로 놓는다.
    - KNeighborsClassifier 클래스 임포트
``` python
# 두 리스트 합치는 과정
length = bream_length + smelt_length
weight = bream_weight + smelt_weight

fish_data = [[l, w] for l, w in zip(length, weight)]
fish_target = [1] * 35 + [0] * 14

from sklearn.neighbors import KNeighborsClassifier
# import한 클래스의 객체 만들기
kn = KNeighborsClassifier()
# 이 객체에 fishdata와 fishtarget을 전달하여 도미 찾는 기준을 학습시킨다.
kn.fit(fish_data, fish_target)
kn.score(fish_data, fish_target)

kn.predict([[30. 600]])

# 만약 근접 이웃 숫자를 바꾸고 싶을 때
# kn2 = KNeighborsClassifier(n_neighbors=49)
# 이 경우 49개 중 도미가 35라서 어떤 데이터를 넣든 도미로 판단할 것.
```
    - kn이라는 객체에 도미 찾는 기준을 학습시키는 것을 훈련training이라 한다.
    - 사이킷런에서는 fit() 메소드가 훈련을 한다.
    - 모델 평가는 score()로 한다. 0~1 사이의 값을 가짐. 정확도accuracy.
    - K-최근접 이웃 알고리즘은 주위 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용하는 것.
    - predict는 새로운 데이터의 정답을 예측한다.
    - fit() 메소드 처럼 리스트의 리스트로 전달해야 해서 2번 감쌌다.
    - 모든 데이터를 가져와서 각각의 거리에 대해 직선거리로 살피기 때문에, 메모리가 많이 필요하고 계산 시간이 많이 필요하다.
    - 무언가 훈련되는 건 없고, 모든 데이터를 갖고 있다가 새로운 데이터가 오면 가장 가까운 데이터를 참고하여 구분하는 것.
    - 기본 값은 5이다. 5개의 주변 데이터로 참고. 이를 변경할 수도 있다.
## 2-1. 훈련 세트와 테스트 세트
- 지도 학습과 비지도 학습
- 훈련 세트와 테스트 세트
- 샘플링 편향
- 넘파이
## 2-2. 데이터 전처리
- 넘파이로 데이터 준비하기
- 수상한 도미 한 마리
- 전처리 데이터로 모델 훈련하기
