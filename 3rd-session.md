# 3주차. 3장. 회귀 알고리즘과 모델 규제(p.114-p.175)

## 3-1. K-최근점 이웃 회귀(p.114)
- 지도학습 알고리즘 -> 1\) 분류와 2\) 회귀로 나뉘어짐.
  - 분류는 샘플은 클래스 중 하나로 분류하는 문제이고 회귀는 임의의 어떤 숫자를 예측하는 문제.
  - 회귀는 1980년 대 Francis Galton이 처음 사용한 용어.
  - K-최근접 이웃 분류 알고리즘과 비슷한 방식. 분류 방식은 이웃의 샘플들 확인해서 그 중 다수 클래스를 샘플의 클래스로 예측하는 것.
  - K-최근접 이웃 회귀도, 이웃한 샘플의 타깃이 클래스가 아니라 임의의 수치인 차이.

### K-최근접 이웃 회귀(p.115)
```python
import numpy as np
perch_length = np.array(
    [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0,
    24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0,
    43.0, 43.5, 44.0]
    )
```
### 데이터 준비(p.116)
### 결정계수 Rsquare(p.120)
### 과대적합 vs 과소적합(p.122)

## 3-2. 선형 회귀(p.130)
### K-최근접 이웃의 한계(p.131)
### 선형 회귀(p.135)
### 다항 회귀(p.139)

## 3-3. 특성 공학과 규제(p.150)
### 다중 회귀(p.151)
### 데이터 준비(p.152)
### 사이킷런의 변환기(p.154)
### 다중 회귀 모델 훈련하기(p.156)
### 규제(p.158)
### 릿지 회귀(p.160)
### 라쏘 회귀(p.163)
